{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quick-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /opt/conda/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-efficiency",
   "metadata": {},
   "source": [
    "# Initial Company Dataset\n",
    "Our dataset imported with LLM summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "square-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>year founded</th>\n",
       "      <th>industry</th>\n",
       "      <th>size range</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>linkedin url</th>\n",
       "      <th>current employee estimate</th>\n",
       "      <th>total employee estimate</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5872184</td>\n",
       "      <td>ibm</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>new york, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/ibm</td>\n",
       "      <td>274047</td>\n",
       "      <td>716906</td>\n",
       "      <td>IBM is a technology and consulting company tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2309813</td>\n",
       "      <td>us army</td>\n",
       "      <td>goarmy.com</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>military</td>\n",
       "      <td>10001+</td>\n",
       "      <td>alexandria, virginia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/us-army</td>\n",
       "      <td>162163</td>\n",
       "      <td>445958</td>\n",
       "      <td>The U.S. Army provides diverse career opportun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2959148</td>\n",
       "      <td>cognizant technology solutions</td>\n",
       "      <td>cognizant.com</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>teaneck, new jersey, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/cognizant</td>\n",
       "      <td>122031</td>\n",
       "      <td>210020</td>\n",
       "      <td>Cognizant helps businesses modernize technolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5944912</td>\n",
       "      <td>walmart</td>\n",
       "      <td>walmartcareers.com</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>10001+</td>\n",
       "      <td>withee, wisconsin, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/walmart</td>\n",
       "      <td>120753</td>\n",
       "      <td>272827</td>\n",
       "      <td>Walmart is a global retailer and employer offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3300741</td>\n",
       "      <td>at&amp;t</td>\n",
       "      <td>att.com</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>telecommunications</td>\n",
       "      <td>10001+</td>\n",
       "      <td>dallas, texas, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/at&amp;t</td>\n",
       "      <td>115188</td>\n",
       "      <td>269659</td>\n",
       "      <td>AT&amp;T is a telecommunications company offering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19800</th>\n",
       "      <td>3278172</td>\n",
       "      <td>bush industries</td>\n",
       "      <td>bush.co</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>furniture</td>\n",
       "      <td>201 - 500</td>\n",
       "      <td>jamestown, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/bush-industries</td>\n",
       "      <td>106</td>\n",
       "      <td>411</td>\n",
       "      <td>Okay, I'm ready. Please provide the website UR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19801</th>\n",
       "      <td>2386412</td>\n",
       "      <td>texas a&amp;m foundation</td>\n",
       "      <td>txamfoundation.com</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>philanthropy</td>\n",
       "      <td>201 - 500</td>\n",
       "      <td>college station, texas, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/texas-a&amp;m-foundation</td>\n",
       "      <td>106</td>\n",
       "      <td>198</td>\n",
       "      <td>The Texas A&amp;M Foundation, established in 1953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19802</th>\n",
       "      <td>4378167</td>\n",
       "      <td>lexicon relocation</td>\n",
       "      <td>lexiconrelocation.com</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>201 - 500</td>\n",
       "      <td>jacksonville, florida, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/lexicon-relocation</td>\n",
       "      <td>106</td>\n",
       "      <td>217</td>\n",
       "      <td>Sterling Lexicon is a global relocation manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19803</th>\n",
       "      <td>4613124</td>\n",
       "      <td>honor</td>\n",
       "      <td>joinhonor.com</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>hospital &amp; health care</td>\n",
       "      <td>201 - 500</td>\n",
       "      <td>san francisco, california, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/joinhonor</td>\n",
       "      <td>106</td>\n",
       "      <td>152</td>\n",
       "      <td>Honor Technology is a healthtech company focus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19804</th>\n",
       "      <td>61429</td>\n",
       "      <td>levine school of music</td>\n",
       "      <td>levinemusic.org</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>music</td>\n",
       "      <td>201 - 500</td>\n",
       "      <td>washington, district of columbia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/levine-school-of-music</td>\n",
       "      <td>106</td>\n",
       "      <td>235</td>\n",
       "      <td>Levine Music is a community music school offer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19805 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            name                 domain  \\\n",
       "0         5872184                             ibm                ibm.com   \n",
       "1         2309813                         us army             goarmy.com   \n",
       "2         2959148  cognizant technology solutions          cognizant.com   \n",
       "3         5944912                         walmart     walmartcareers.com   \n",
       "4         3300741                            at&t                att.com   \n",
       "...           ...                             ...                    ...   \n",
       "19800     3278172                 bush industries                bush.co   \n",
       "19801     2386412            texas a&m foundation     txamfoundation.com   \n",
       "19802     4378167              lexicon relocation  lexiconrelocation.com   \n",
       "19803     4613124                           honor          joinhonor.com   \n",
       "19804       61429          levine school of music        levinemusic.org   \n",
       "\n",
       "       year founded                             industry size range  \\\n",
       "0            1911.0  information technology and services     10001+   \n",
       "1            1800.0                             military     10001+   \n",
       "2            1994.0  information technology and services     10001+   \n",
       "3            1962.0                               retail     10001+   \n",
       "4            1876.0                   telecommunications     10001+   \n",
       "...             ...                                  ...        ...   \n",
       "19800        1957.0                            furniture  201 - 500   \n",
       "19801        1953.0                         philanthropy  201 - 500   \n",
       "19802        1993.0                          real estate  201 - 500   \n",
       "19803        2014.0               hospital & health care  201 - 500   \n",
       "19804        1976.0                                music  201 - 500   \n",
       "\n",
       "                                              locality        country  \\\n",
       "0                    new york, new york, united states  united states   \n",
       "1                  alexandria, virginia, united states  united states   \n",
       "2                   teaneck, new jersey, united states  united states   \n",
       "3                     withee, wisconsin, united states  united states   \n",
       "4                         dallas, texas, united states  united states   \n",
       "...                                                ...            ...   \n",
       "19800               jamestown, new york, united states  united states   \n",
       "19801            college station, texas, united states  united states   \n",
       "19802             jacksonville, florida, united states  united states   \n",
       "19803         san francisco, california, united states  united states   \n",
       "19804  washington, district of columbia, united states  united states   \n",
       "\n",
       "                                      linkedin url  current employee estimate  \\\n",
       "0                         linkedin.com/company/ibm                     274047   \n",
       "1                     linkedin.com/company/us-army                     162163   \n",
       "2                   linkedin.com/company/cognizant                     122031   \n",
       "3                     linkedin.com/company/walmart                     120753   \n",
       "4                        linkedin.com/company/at&t                     115188   \n",
       "...                                            ...                        ...   \n",
       "19800         linkedin.com/company/bush-industries                        106   \n",
       "19801    linkedin.com/company/texas-a&m-foundation                        106   \n",
       "19802      linkedin.com/company/lexicon-relocation                        106   \n",
       "19803               linkedin.com/company/joinhonor                        106   \n",
       "19804  linkedin.com/company/levine-school-of-music                        106   \n",
       "\n",
       "       total employee estimate  \\\n",
       "0                       716906   \n",
       "1                       445958   \n",
       "2                       210020   \n",
       "3                       272827   \n",
       "4                       269659   \n",
       "...                        ...   \n",
       "19800                      411   \n",
       "19801                      198   \n",
       "19802                      217   \n",
       "19803                      152   \n",
       "19804                      235   \n",
       "\n",
       "                                                 summary  \n",
       "0      IBM is a technology and consulting company tha...  \n",
       "1      The U.S. Army provides diverse career opportun...  \n",
       "2      Cognizant helps businesses modernize technolog...  \n",
       "3      Walmart is a global retailer and employer offe...  \n",
       "4      AT&T is a telecommunications company offering ...  \n",
       "...                                                  ...  \n",
       "19800  Okay, I'm ready. Please provide the website UR...  \n",
       "19801  The Texas A&M Foundation, established in 1953,...  \n",
       "19802  Sterling Lexicon is a global relocation manage...  \n",
       "19803  Honor Technology is a healthtech company focus...  \n",
       "19804  Levine Music is a community music school offer...  \n",
       "\n",
       "[19805 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('company_summaries.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "celtic-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aware-interim",
   "metadata": {},
   "source": [
    "# Creating a custom stemmer\n",
    "Creating a stemming function to remove all punctuation and remove all stop words from LLM summary. It is important to stem the words consistently to highlight similarities across different comapny descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokenizer(text):\n",
    "    no_punc = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(no_punc.lower())\n",
    "    return [stemmer.stem(word) for word in tokens if word not in ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-appraisal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hired-criterion",
   "metadata": {},
   "source": [
    "# TF-IDF vectorization\n",
    "Tf-IDF vectorization of LLM summaries and appending them to baseline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minimal-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df = 10, ngram_range = (1,3), tokenizer = stem_tokenizer)\n",
    "tfidf_mat = vect.fit_transform(df.summary)\n",
    "mat_as_df = pd.DataFrame.sparse.from_spmatrix(tfidf_mat)\n",
    "final_df = pd.concat([df, mat_as_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greatest-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>year founded</th>\n",
       "      <th>industry</th>\n",
       "      <th>size range</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>linkedin url</th>\n",
       "      <th>current employee estimate</th>\n",
       "      <th>...</th>\n",
       "      <th>20335</th>\n",
       "      <th>20336</th>\n",
       "      <th>20337</th>\n",
       "      <th>20338</th>\n",
       "      <th>20339</th>\n",
       "      <th>20340</th>\n",
       "      <th>20341</th>\n",
       "      <th>20342</th>\n",
       "      <th>20343</th>\n",
       "      <th>20344</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5872184</td>\n",
       "      <td>ibm</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>new york, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/ibm</td>\n",
       "      <td>274047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2309813</td>\n",
       "      <td>us army</td>\n",
       "      <td>goarmy.com</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>military</td>\n",
       "      <td>10001+</td>\n",
       "      <td>alexandria, virginia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/us-army</td>\n",
       "      <td>162163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2959148</td>\n",
       "      <td>cognizant technology solutions</td>\n",
       "      <td>cognizant.com</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>teaneck, new jersey, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/cognizant</td>\n",
       "      <td>122031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5944912</td>\n",
       "      <td>walmart</td>\n",
       "      <td>walmartcareers.com</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>10001+</td>\n",
       "      <td>withee, wisconsin, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/walmart</td>\n",
       "      <td>120753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3300741</td>\n",
       "      <td>at&amp;t</td>\n",
       "      <td>att.com</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>telecommunications</td>\n",
       "      <td>10001+</td>\n",
       "      <td>dallas, texas, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/at&amp;t</td>\n",
       "      <td>115188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            name              domain  \\\n",
       "0     5872184                             ibm             ibm.com   \n",
       "1     2309813                         us army          goarmy.com   \n",
       "2     2959148  cognizant technology solutions       cognizant.com   \n",
       "3     5944912                         walmart  walmartcareers.com   \n",
       "4     3300741                            at&t             att.com   \n",
       "\n",
       "   year founded                             industry size range  \\\n",
       "0        1911.0  information technology and services     10001+   \n",
       "1        1800.0                             military     10001+   \n",
       "2        1994.0  information technology and services     10001+   \n",
       "3        1962.0                               retail     10001+   \n",
       "4        1876.0                   telecommunications     10001+   \n",
       "\n",
       "                              locality        country  \\\n",
       "0    new york, new york, united states  united states   \n",
       "1  alexandria, virginia, united states  united states   \n",
       "2   teaneck, new jersey, united states  united states   \n",
       "3     withee, wisconsin, united states  united states   \n",
       "4         dallas, texas, united states  united states   \n",
       "\n",
       "                     linkedin url  current employee estimate  ...  20335  \\\n",
       "0        linkedin.com/company/ibm                     274047  ...    0.0   \n",
       "1    linkedin.com/company/us-army                     162163  ...    0.0   \n",
       "2  linkedin.com/company/cognizant                     122031  ...    0.0   \n",
       "3    linkedin.com/company/walmart                     120753  ...    0.0   \n",
       "4       linkedin.com/company/at&t                     115188  ...    0.0   \n",
       "\n",
       "  20336  20337  20338  20339  20340  20341  20342  20343  20344  \n",
       "0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 20357 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "yellow-witch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>year founded</th>\n",
       "      <th>industry</th>\n",
       "      <th>size range</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>linkedin url</th>\n",
       "      <th>current employee estimate</th>\n",
       "      <th>total employee estimate</th>\n",
       "      <th>...</th>\n",
       "      <th>20335</th>\n",
       "      <th>20336</th>\n",
       "      <th>20337</th>\n",
       "      <th>20338</th>\n",
       "      <th>20339</th>\n",
       "      <th>20340</th>\n",
       "      <th>20341</th>\n",
       "      <th>20342</th>\n",
       "      <th>20343</th>\n",
       "      <th>20344</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ibm</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>new york, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/ibm</td>\n",
       "      <td>274047</td>\n",
       "      <td>716906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us army</td>\n",
       "      <td>goarmy.com</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>military</td>\n",
       "      <td>10001+</td>\n",
       "      <td>alexandria, virginia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/us-army</td>\n",
       "      <td>162163</td>\n",
       "      <td>445958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cognizant technology solutions</td>\n",
       "      <td>cognizant.com</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>teaneck, new jersey, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/cognizant</td>\n",
       "      <td>122031</td>\n",
       "      <td>210020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walmart</td>\n",
       "      <td>walmartcareers.com</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>10001+</td>\n",
       "      <td>withee, wisconsin, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/walmart</td>\n",
       "      <td>120753</td>\n",
       "      <td>272827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at&amp;t</td>\n",
       "      <td>att.com</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>telecommunications</td>\n",
       "      <td>10001+</td>\n",
       "      <td>dallas, texas, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/at&amp;t</td>\n",
       "      <td>115188</td>\n",
       "      <td>269659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name              domain  year founded  \\\n",
       "0                             ibm             ibm.com        1911.0   \n",
       "1                         us army          goarmy.com        1800.0   \n",
       "2  cognizant technology solutions       cognizant.com        1994.0   \n",
       "3                         walmart  walmartcareers.com        1962.0   \n",
       "4                            at&t             att.com        1876.0   \n",
       "\n",
       "                              industry size range  \\\n",
       "0  information technology and services     10001+   \n",
       "1                             military     10001+   \n",
       "2  information technology and services     10001+   \n",
       "3                               retail     10001+   \n",
       "4                   telecommunications     10001+   \n",
       "\n",
       "                              locality        country  \\\n",
       "0    new york, new york, united states  united states   \n",
       "1  alexandria, virginia, united states  united states   \n",
       "2   teaneck, new jersey, united states  united states   \n",
       "3     withee, wisconsin, united states  united states   \n",
       "4         dallas, texas, united states  united states   \n",
       "\n",
       "                     linkedin url  current employee estimate  \\\n",
       "0        linkedin.com/company/ibm                     274047   \n",
       "1    linkedin.com/company/us-army                     162163   \n",
       "2  linkedin.com/company/cognizant                     122031   \n",
       "3    linkedin.com/company/walmart                     120753   \n",
       "4       linkedin.com/company/at&t                     115188   \n",
       "\n",
       "   total employee estimate  ... 20335  20336  20337  20338  20339  20340  \\\n",
       "0                   716906  ...   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1                   445958  ...   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2                   210020  ...   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3                   272827  ...   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4                   269659  ...   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   20341  20342  20343  20344  \n",
       "0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 20356 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.drop('Unnamed: 0', axis = 1)\n",
    "final_df = final_df.dropna()\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intensive-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>year founded</th>\n",
       "      <th>industry</th>\n",
       "      <th>size range</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>linkedin url</th>\n",
       "      <th>current employee estimate</th>\n",
       "      <th>...</th>\n",
       "      <th>20335</th>\n",
       "      <th>20336</th>\n",
       "      <th>20337</th>\n",
       "      <th>20338</th>\n",
       "      <th>20339</th>\n",
       "      <th>20340</th>\n",
       "      <th>20341</th>\n",
       "      <th>20342</th>\n",
       "      <th>20343</th>\n",
       "      <th>20344</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ibm</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>new york, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/ibm</td>\n",
       "      <td>274047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>us army</td>\n",
       "      <td>goarmy.com</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>military</td>\n",
       "      <td>10001+</td>\n",
       "      <td>alexandria, virginia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/us-army</td>\n",
       "      <td>162163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cognizant technology solutions</td>\n",
       "      <td>cognizant.com</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>teaneck, new jersey, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/cognizant</td>\n",
       "      <td>122031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>walmart</td>\n",
       "      <td>walmartcareers.com</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>10001+</td>\n",
       "      <td>withee, wisconsin, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/walmart</td>\n",
       "      <td>120753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>at&amp;t</td>\n",
       "      <td>att.com</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>telecommunications</td>\n",
       "      <td>10001+</td>\n",
       "      <td>dallas, texas, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/at&amp;t</td>\n",
       "      <td>115188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                            name              domain  year founded  \\\n",
       "0      0                             ibm             ibm.com        1911.0   \n",
       "1      1                         us army          goarmy.com        1800.0   \n",
       "2      2  cognizant technology solutions       cognizant.com        1994.0   \n",
       "3      3                         walmart  walmartcareers.com        1962.0   \n",
       "4      4                            at&t             att.com        1876.0   \n",
       "\n",
       "                              industry size range  \\\n",
       "0  information technology and services     10001+   \n",
       "1                             military     10001+   \n",
       "2  information technology and services     10001+   \n",
       "3                               retail     10001+   \n",
       "4                   telecommunications     10001+   \n",
       "\n",
       "                              locality        country  \\\n",
       "0    new york, new york, united states  united states   \n",
       "1  alexandria, virginia, united states  united states   \n",
       "2   teaneck, new jersey, united states  united states   \n",
       "3     withee, wisconsin, united states  united states   \n",
       "4         dallas, texas, united states  united states   \n",
       "\n",
       "                     linkedin url  current employee estimate  ...  20335  \\\n",
       "0        linkedin.com/company/ibm                     274047  ...    0.0   \n",
       "1    linkedin.com/company/us-army                     162163  ...    0.0   \n",
       "2  linkedin.com/company/cognizant                     122031  ...    0.0   \n",
       "3    linkedin.com/company/walmart                     120753  ...    0.0   \n",
       "4       linkedin.com/company/at&t                     115188  ...    0.0   \n",
       "\n",
       "  20336  20337  20338  20339  20340  20341  20342  20343  20344  \n",
       "0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 20357 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.reset_index()\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-cameroon",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "The dataset is now too large and needs to be reduced. The dataset is reduced to 10 principal components and appended with their names as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "name = final_df['name']\n",
    "\n",
    "tobe_pca_df = final_df.drop(labels=['name', 'domain', 'industry', 'size range', 'locality', 'country', 'linkedin url', 'summary'], axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(tobe_pca_df)\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "pca.fit(scaled_df)\n",
    "pca_data = pca.transform(scaled_df)\n",
    "\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10'])\n",
    "pca_df['name'] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-cable",
   "metadata": {},
   "source": [
    "# Exporting PCA dataset to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bronze-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 677.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Split the DataFrame into chunks\n",
    "pca_chunks = np.array_split(pca_df, 200)\n",
    "\n",
    "# Save each chunk to CSV with progress tracking\n",
    "with open('pca_data.csv', 'w') as f:\n",
    "    for i, chunk in enumerate(tqdm(pca_chunks)):\n",
    "        if i == 0:\n",
    "            chunk.to_csv(f, index=False)\n",
    "        else:\n",
    "            chunk.to_csv(f, header=False, index=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-membrane",
   "metadata": {},
   "source": [
    "# Exporting raw data\n",
    "Attempt to extract the raw data to be compared against with the clustering. THe dataset was too large, and this process could not be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_chunks = np.array_split(final_df, 10000)\n",
    "with open('raw_data.csv', 'w') as f:\n",
    "    for i, raw_chunk in enumerate(tqdm(raw_chunks)):\n",
    "        if i == 0:\n",
    "            raw_chunk.to_csv(f, index=False)\n",
    "        else:\n",
    "            raw_chunk.to_csv(f, header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-anthropology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
